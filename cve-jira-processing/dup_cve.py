#!/usr/bin/env python3
"""CVE duplicate detection and handling for Jira issues."""

import argparse
import logging
import re
from collections import defaultdict
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional

import yaml

from lib.jira_client import JiraTool


logger = logging.getLogger(__name__)

# Default config file location (same directory as script)
DEFAULT_CONFIG_PATH = Path(__file__).parent / "config.yaml"


def load_config(config_path: Path) -> dict:
    """Load configuration from YAML file."""
    if not config_path.exists():
        raise FileNotFoundError(f"Config file not found: {config_path}")

    with open(config_path, "r") as f:
        config = yaml.safe_load(f)

    # Validate required keys
    required_keys = ["cve_processed_label", "repo_to_component"]
    for key in required_keys:
        if key not in config:
            raise ValueError(f"Missing required config key: {key}")

    return config


@dataclass
class ComplexBug:
    key: str
    components: list
    affected_version: list
    cve_id: str


@dataclass
class VersionGroup:
    """Group of bugs for a specific version within a CVE."""

    version: str
    bugs: List[ComplexBug]


@dataclass
class CVEGroup:
    """Group of bugs for a CVE/component combination across versions."""

    cve_id: str
    component: str
    components_list: list  # Jira components for issue creation
    version_groups: Dict[str, VersionGroup]
    epic_key: Optional[str] = None


@dataclass
class ProcessedResult:
    """Result of processing a CVE group."""

    epic_key: str
    cve_id: str
    component: str
    tasks: List[str]
    bugs: List[str]
    cves_linked: List[str]


def parse_numeric_version(version: str) -> Optional[tuple]:
    """
    Parse a version string to extract numeric major.minor parts.

    Handles versions like "4.12", "4.15.z", "4.16.0", etc.
    Returns tuple (major, minor) or None if not a valid numeric version.
    """
    # Match X.Y optionally followed by .z or .0 or similar
    match = re.match(r"^(\d+)\.(\d+)(?:\.\w+)?$", version)
    if match:
        return (int(match.group(1)), int(match.group(2)))
    return None


def normalize_version(version: str) -> str:
    """
    Normalize a version string to X.Y format.

    Strips suffixes like .z, .0, etc.
    """
    parsed = parse_numeric_version(version)
    if parsed:
        return f"{parsed[0]}.{parsed[1]}"
    return version


def get_sorted_versions(version_names: List[str]) -> List[str]:
    """
    Filter and sort version names to only include numeric versions.

    Returns sorted unique normalized versions like ["4.12", "4.13", "4.14",
        "4.15"].
    """
    numeric_versions = set()
    for name in version_names:
        parsed = parse_numeric_version(name)
        if parsed:
            # Normalize to X.Y format to deduplicate 4.14 and 4.14.z
            numeric_versions.add(normalize_version(name))

    return sorted(numeric_versions, key=lambda v: parse_numeric_version(v))


def get_versions_in_range(
    min_version: str, max_version: str, available_versions: List[str]
) -> List[str]:
    """
    Get all versions between min and max (inclusive) from available versions.

    Args:
        min_version: The minimum version (e.g., "4.12")
        max_version: The maximum version (e.g., "4.17")
        available_versions: Sorted list of available versions

    Returns:
        List of versions in range, sorted.
    """
    min_parsed = parse_numeric_version(min_version)
    max_parsed = parse_numeric_version(max_version)

    if not min_parsed or not max_parsed:
        return []

    result = []
    for version in available_versions:
        parsed = parse_numeric_version(version)
        if parsed and min_parsed <= parsed <= max_parsed:
            result.append(version)

    return result


def group_issues_by_cve(
    issues: List[dict], repo_to_component: Dict[str, str]
) -> Dict[str, CVEGroup]:
    """
    Group issues by CVE and component, then by version within each group.

    Args:
        issues: List of issue data dictionaries (each with 'key' field).
        repo_to_component: Mapping of downstream repo names to component names.

    Returns a dict where keys are "component:cve_id" and values are
    CVEGroup instances containing version-grouped bugs.
    """
    # First pass: collect all bugs
    temp_groups: Dict[str, Dict[str, List[ComplexBug]]] = defaultdict(
        lambda: defaultdict(list)
    )
    components_map: Dict[str, list] = {}

    for issue in issues:
        bug_key = issue["key"]
        downstream_component = issue.get("Downstream Component Name")
        if downstream_component not in repo_to_component:
            logger.warning(
                "Skipping %s: unknown component %s",bug_key, downstream_component
            )
            continue

        component = repo_to_component[downstream_component]
        raw_version = issue["Affects Version/s"][0]["name"]
        version = normalize_version(raw_version)
        cve_id = issue["CVE ID"]

        group_key = f"{component}:{cve_id}"
        bug = ComplexBug(
            key=bug_key,
            components=issue["Component/s"],
            affected_version=issue["Affects Version/s"],
            cve_id=cve_id,
        )
        temp_groups[group_key][version].append(bug)

        # Store components for issue creation (use first bug's components)
        if group_key not in components_map:
            components_map[group_key] = issue["Component/s"]

    # Second pass: build CVEGroup objects
    result = {}
    for group_key, version_dict in temp_groups.items():
        component, cve_id = group_key.rsplit(":", 1)
        version_groups = {
            ver: VersionGroup(version=ver, bugs=bugs)
            for ver, bugs in version_dict.items()
        }
        result[group_key] = CVEGroup(
            cve_id=cve_id,
            component=component,
            components_list=components_map[group_key],
            version_groups=version_groups,
        )

    return result


# =============================================================================
# Query functions
# =============================================================================


def query_vulnerabilities(
    client: JiraTool,
    downstream_components: List[str],
    cve_processed_label: str,
    cve_filter: Optional[str] = None,
) -> List[dict]:
    """
    Query Jira for all unprocessed Vulnerability issues for given components.

    Args:
        client: Jira client.
        downstream_components: List of downstream component names to query.
        cve_processed_label: Label that marks already-processed CVEs.
        cve_filter: Optional CVE ID to filter for (e.g., "CVE-2024-1234").

    Returns:
        List of issue data dictionaries.
    """
    # Build component conditions with OR (only ~ operator is supported)
    component_conditions = " OR ".join(
        f'"Downstream Component Name" ~ "{c}"' for c in downstream_components
    )

    jql = (
        f"project = OCPBUGS AND type = Vulnerability "
        f"AND ({component_conditions}) "
        f'AND labels != "{cve_processed_label}" '
        f"AND status IN (New, ASSIGNED)"
    )

    # Add CVE ID filter if specified
    if cve_filter:
        jql += f' AND "CVE ID" ~ "{cve_filter}"'

    logger.info("Querying Jira for Vulnerabilities...")
    logger.debug("JQL: %s", jql)

    # Fetch all fields in single query (optimized - 1 request instead of N+1)
    fields = [
        "Affects Version/s",
        "CVE ID",
        "Downstream Component Name",
        "Component/s",
        "Issue Type",
        "Labels",
    ]
    issues = client.search_issues_as_dicts(
        jql, fields=fields, max_results=1000)
    logger.info("Found %d unprocessed Vulnerabilities", len(issues))

    return issues


# =============================================================================
# Search functions
# =============================================================================


def query_all_cves_for_cve_id(
    client: JiraTool, cve_id: str, downstream_components: List[str]
) -> Dict[str, List[dict]]:
    """
    Query for CVEs with a specific CVE ID, excluding closed/fixed ones.

    This finds all versions where this CVE exists across the given components.
    Excludes CVEs that are closed (unless closed as Duplicate/Won't Do/Not a
    Bug).

    Args:
        client: Jira client.
        cve_id: The CVE identifier (e.g., "CVE-2024-1234").
        downstream_components: List of downstream component names.

    Returns:
        Dictionary mapping version -> list of CVE issue data.
    """
    # Build component conditions
    component_conditions = " OR ".join(
        f'"Downstream Component Name" ~ "{c}"' for c in downstream_components
    )

    # Exclude closed CVEs unless they were closed as Duplicate/Won't Do/Not a
    # Bug This way we still track versions with unresolved CVEs
    jql = (
        f"project = OCPBUGS AND type = Vulnerability "
        f'AND "CVE ID" ~ "{cve_id}" '
        f"AND ({component_conditions}) "
        f"AND (status != Closed OR resolution IN "
        f'(Duplicate, "Won\'t Do", "Not a Bug"))'
    )

    logger.debug("Querying all CVEs for %s: %s", cve_id, jql)

    # Fetch all fields in single query (optimized - 1 request instead of N+1)
    fields = [
        "Affects Version/s",
        "CVE ID",
        "Downstream Component Name",
        "Component/s",
        "Labels",
    ]
    issues = client.search_issues_as_dicts(
        jql, fields=fields, max_results=1000)

    result: Dict[str, List[dict]] = {}
    for issue_data in issues:
        # Extract version and normalize (e.g., "4.15.z" -> "4.15")
        affects = issue_data.get("Affects Version/s", [])
        if affects:
            raw_version = affects[0]["name"]
            version = normalize_version(raw_version)
            if version not in result:
                result[version] = []
            result[version].append(issue_data)

    return result


@dataclass
class ExistingIssuesCache:
    """Cache of existing issues for a CVE/component."""

    epic_key: Optional[str] = None
    tasks_by_version: Dict[str, str] = None  # version -> task key
    bugs_by_version: Dict[str, str] = None  # version -> bug key

    def __post_init__(self):
        if self.tasks_by_version is None:
            self.tasks_by_version = {}
        if self.bugs_by_version is None:
            self.bugs_by_version = {}


def find_all_existing_issues(
    client: JiraTool, cve_id: str, component: str, project: str
) -> ExistingIssuesCache:
    """
    Find all existing issues for a CVE/component in a single batch query.

    This is more efficient than individual lookups (1 query instead of N).

    Args:
        client: Jira client.
        cve_id: The CVE identifier.
        component: The component name.

    Returns:
        ExistingIssuesCache with found issues.
    """
    cache = ExistingIssuesCache()
    summary_prefix = f"{cve_id} - {component}"
    escaped_prefix = summary_prefix.replace('"', '\\"')

    # Query project for epics and tasks
    jql_project = (
        f"project = {project} AND type IN (Epic, Task) "
        f'AND summary ~ "\\"{escaped_prefix}\\""'
    )
    project_issues = client.search_issues(
        jql_project, fields=["summary", "issuetype"], max_results=100
    )

    for issue in project_issues:
        issue_type = issue.fields.issuetype.name
        summary = issue.fields.summary

        if issue_type == "Epic" and summary == summary_prefix:
            cache.epic_key = issue.key
        elif issue_type == "Task" and summary.startswith(summary_prefix + " - "):
            # Extract version from "CVE-ID - component - version"
            version = summary[len(summary_prefix) + 3:]
            cache.tasks_by_version[version] = issue.key

    # Query OCPBUGS for bugs
    jql_ocpbugs = (
        f"project = OCPBUGS AND type = Bug " f'AND summary ~ "\\"{escaped_prefix}\\""'
    )
    ocpbugs_issues = client.search_issues(
        jql_ocpbugs, fields=["summary"], max_results=100
    )

    for issue in ocpbugs_issues:
        summary = issue.fields.summary
        if summary.startswith(summary_prefix + " - "):
            version = summary[len(summary_prefix) + 3:]
            cache.bugs_by_version[version] = issue.key

    logger.debug(
        "Found existing: epic=%s, %d tasks, %d bugs",
        cache.epic_key,
        len(cache.tasks_by_version),
        len(cache.bugs_by_version),
    )
    return cache


# =============================================================================
# Creation functions
# =============================================================================


def find_or_create_epic(
    client: JiraTool,
    cve_id: str,
    component: str,
    cache: ExistingIssuesCache,
    project: str,
    dry_run: bool = False,
) -> str:
    """Find an existing Epic or create a new one for a CVE/component."""
    epic_summary = f"{cve_id} - {component}"

    # Check cache first
    if cache.epic_key:
        logger.info("  Found existing Epic: %s", cache.epic_key)
        return cache.epic_key

    if dry_run:
        logger.info("  [DRY RUN] Would create Epic: %s", epic_summary)
        return f"{project}-NEW({epic_summary})"

    epic_description = (
        f"Tracking epic for {cve_id} affecting {component}.\n\n"
        f"This epic groups all version-specific tasks for this CVE/component combination.\n"
        f"Each task tracks the fix status for a specific OpenShift version."
    )

    epic = client.create_jira_issue(
        {
            "project": project,
            "Epic Name": epic_summary,
            "summary": epic_summary,
            "security level": "Red Hat Employee",
            "assignee": client.get_current_user(),
            "Description": epic_description,
        },
        "Epic",
    )
    logger.info("  Created Epic: %s", epic.key)
    return epic.key


def create_task(
    client: JiraTool,
    cve_id: str,
    component: str,
    version: str,
    epic_key: str,
    cache: ExistingIssuesCache,
    project: str,
    dry_run: bool = False,
) -> Optional[str]:
    """
    Create a Task for tracking a CVE/component/version.

    Returns the task key or a descriptive placeholder in dry-run mode.
    """
    task_summary = f"{cve_id} - {component} - {version}"

    # Check cache first
    existing = cache.tasks_by_version.get(version)
    if existing:
        logger.info("    Found existing task: %s", existing)
        return existing

    if dry_run:
        logger.info("    [DRY RUN] Would create task: %s", task_summary)
        return f"{project}-NEW({task_summary})"

    task_description = (
        f"Tracking task for {cve_id} in {component} for OpenShift {version}.\n\n"
        f"This task tracks the remediation status of the CVE for this specific version.\n"
        f"Linked CVE issues (if any) represent the upstream vulnerability reports."
    )

    task_fields = {
        "project": project,
        "summary": task_summary,
        "security level": "Red Hat Employee",
        "assignee": client.get_current_user(),
        "Description": task_description,
    }

    # Add epic link if epic exists (not a dry-run placeholder)
    if epic_key and not is_dry_run_key(epic_key):
        task_fields["Epic Link"] = epic_key

    task = client.create_jira_issue(task_fields, "Task")
    logger.info("    Created task: %s", task.key)
    return task.key


def create_verified_bug(
    client: JiraTool,
    cve_id: str,
    component: str,
    version: str,
    components: List[str],
    cache: ExistingIssuesCache,
    is_latest_version: bool = False,
    dry_run: bool = False,
) -> Optional[str]:
    """
    Create a VERIFIED Bug in OCPBUGS for CVE verification.

    This bug indicates that the CVE was verified as not affecting this version.

    Returns the bug key or a descriptive placeholder in dry-run mode.
    """
    bug_summary = f"{cve_id} - {component} - {version}"

    # Check cache first
    existing = cache.bugs_by_version.get(version)
    if existing:
        logger.info("    Found existing bug: %s", existing)
        return existing

    # Latest version doesn't have .z suffix
    target_version = version if is_latest_version else version + ".z"

    if dry_run:
        logger.info("    [DRY RUN] Would create VERIFIED bug: %s", bug_summary)
        return f"OCPBUGS-NEW({bug_summary})"

    bug_description = (
        f"Verification bug for {cve_id} in {component} for OpenShift {version}.\n\n"
        f"This version was verified as not affected by the CVE.\n"
        f"The fix was applied in a previous version and this version inherits it."
    )

    issue_fields = {
        "project": "OCPBUGS",
        "summary": bug_summary,
        "Description": bug_description,
        "component/s": components,
        "security level": "Red Hat Employee",
        "assignee": client.get_current_user(),
        "target version": [target_version],
        "Affects Version/s": [target_version],
        "labels": ["bugwatcher-ignore"],
    }

    bug = client.create_jira_issue(issue_fields, "Bug")
    logger.info("    Created bug: %s", bug.key)

    # Transition to VERIFIED
    client.transition_issue_status(bug.key, "VERIFIED")
    logger.info("    Transitioned %s to VERIFIED", bug.key)

    return bug.key


# =============================================================================
# Linking functions
# =============================================================================


def is_dry_run_key(key: str) -> bool:
    """Check if a key is a dry-run placeholder."""
    return "-NEW(" in key


def link_task_to_bug(
    client: JiraTool, task_key: str, bug_key: str, dry_run: bool = False
) -> None:
    """Link a task to its corresponding OCPBUGS bug."""
    if dry_run or is_dry_run_key(task_key) or is_dry_run_key(bug_key):
        return

    client.link_issue("is related to", task_key, bug_key)
    logger.debug("    Linked task %s to bug %s", task_key, bug_key)


def link_task_to_cves(
    client: JiraTool, task_key: str, cve_keys: List[str], dry_run: bool = False
) -> None:
    """Link a task to all related CVE issues."""
    if dry_run or is_dry_run_key(task_key):
        return

    for cve_key in cve_keys:
        # Task is caused by CVE: link_issue(type, A, B) creates A "is caused by" B
        client.link_issue("is caused by", task_key, cve_key)
        logger.debug("    Linked task %s is caused by CVE %s", task_key, cve_key)


@dataclass
class VersionIssue:
    """Issue info for dependency linking."""

    key: str
    downstream_component: str


def link_version_dependencies(
    client: JiraTool,
    issues_by_version: Dict[str, List[VersionIssue]],
    available_versions: List[str],
    dry_run: bool = False,
) -> None:
    """
    Link issues with 'depends on' relationship: newer depends on older.

    Issues can be CVEs (Vulnerabilities) or created bugs.
    For example: 4.17 depends on 4.16 depends on 4.15
    Prioritizes linking to issues with the same downstream component.
    Falls back to linking to one issue if no same-component match exists.
    """
    # Get versions in order (already sorted)
    versions_with_issues = [
        v for v in available_versions if v in issues_by_version]

    if not versions_with_issues:
        return

    if dry_run:
        logger.info("  [DRY RUN] Dependency chain:")
        for i, version in enumerate(versions_with_issues[:-1]):
            next_version = versions_with_issues[i + 1]
            current_issues = issues_by_version[version]
            next_issues = issues_by_version[next_version]
            logger.info(
                "    %d issues in %s -> depends on -> %d issues in %s",
                len(current_issues),
                version,
                len(next_issues),
                next_version,
            )
        return

    for i, version in enumerate(versions_with_issues[:-1]):
        next_version = versions_with_issues[i + 1]
        current_issues = issues_by_version[version]
        next_issues = issues_by_version[next_version]

        for current_issue in current_issues:
            if is_dry_run_key(current_issue.key):
                continue

            # Find issues in next version with same downstream component
            same_component_issues = [
                ni
                for ni in next_issues
                if ni.downstream_component == current_issue.downstream_component
                and not is_dry_run_key(ni.key)
            ]

            if same_component_issues:
                # Link to all issues with same component
                for next_issue in same_component_issues:
                    # Older version depends on newer version
                    # link_issue(type, A, B) creates: A "depends on" B
                    client.link_issue(
                        "depends on", current_issue.key, next_issue.key)
                    logger.info(
                        "    Linked %s (%s) depends on %s (%s) [same component]",
                        current_issue.key,
                        version,
                        next_issue.key,
                        next_version,
                    )
            else:
                # Fall back to linking to first available issue in next version
                fallback_issues = [
                    ni for ni in next_issues if not is_dry_run_key(ni.key)
                ]
                if fallback_issues:
                    next_issue = fallback_issues[0]
                    # Older version depends on newer version
                    # link_issue(type, A, B) creates: A "depends on" B
                    client.link_issue(
                        "depends on", current_issue.key, next_issue.key)
                    logger.info(
                        "    Linked %s (%s) depends on %s (%s) [fallback]",
                        current_issue.key,
                        version,
                        next_issue.key,
                        next_version,
                    )


# =============================================================================
# Main processing
# =============================================================================


def get_downstream_components_for_upstream(
    upstream_component: str, repo_to_component: Dict[str, str]
) -> List[str]:
    """
    Get all downstream component names that map to a specific upstream
    component.

    Args:
        upstream_component: The upstream component name
            (e.g., "openstack-cinder").
        repo_to_component: Mapping of downstream repo names to upstream
            components.

    Returns:
        List of downstream component names that map to this upstream component.
    """
    return [
        downstream
        for downstream, upstream in repo_to_component.items()
        if upstream == upstream_component
    ]


def process_cve_group(
    client: JiraTool,
    cve_group: CVEGroup,
    available_versions: List[str],
    repo_to_component: Dict[str, str],
    cve_processed_label: str,
    project: str,
    dry_run: bool = False,
) -> ProcessedResult:
    """
    Process a single CVE group.

    Creates:
    1. Epic in OSASINFRA
    2. Task per version in OSASINFRA (linked to CVEs or created bug)
    3. ON_QA Bug in OCPBUGS only for versions WITHOUT CVEs
    4. Dependency chain between issues (CVE or bug, newer depends on older)
    5. Links between tasks and their version's main issue
    """
    logger.info("Processing CVE group: %s:%s",
                cve_group.component, cve_group.cve_id)
    logger.info("  CVE: %s, Component: %s",
                cve_group.cve_id, cve_group.component)

    # Batch query for all existing issues (2 queries instead of N)
    cache = find_all_existing_issues(
        client, cve_group.cve_id, cve_group.component, project)

    # Find or create Epic
    epic_key = find_or_create_epic(
        client, cve_group.cve_id, cve_group.component, cache, project, dry_run
    )

    components = [x["name"] for x in cve_group.components_list]

    # Get downstream components relevant to this upstream component
    relevant_downstream = get_downstream_components_for_upstream(
        cve_group.component, repo_to_component
    )

    # Query for ALL CVEs with this CVE ID (processed and unprocessed)
    # This gives us the complete picture of which versions have CVEs
    # This is a read-only query, safe to run in dry-run mode
    all_cves_by_version = query_all_cves_for_cve_id(
        client, cve_group.cve_id, relevant_downstream
    )
    logger.info("  Found CVEs in versions: %s",
                list(all_cves_by_version.keys()))

    # Determine version range from all known CVEs
    all_cve_versions = set(all_cves_by_version.keys())

    if not all_cve_versions or not available_versions:
        return ProcessedResult(
            epic_key=epic_key,
            cve_id=cve_group.cve_id,
            component=cve_group.component,
            tasks=[],
            bugs=[],
            cves_linked=[],
        )

    # Get min/max CVE versions
    min_version = min(
        all_cve_versions, key=lambda v: parse_numeric_version(v) or (0, 0)
    )
    max_cve_version = max(
        all_cve_versions, key=lambda v: parse_numeric_version(v) or (0, 0)
    )

    # Only process versions that have CVEs
    cve_versions = get_versions_in_range(
        min_version, max_cve_version, available_versions)
    logger.info("  Processing CVE versions: %s", cve_versions)

    # Find next version after max CVE for VERIFIED bug
    next_version = None
    max_idx = available_versions.index(max_cve_version) if max_cve_version in available_versions else -1
    if max_idx >= 0 and max_idx + 1 < len(available_versions):
        next_version = available_versions[max_idx + 1]
        logger.info("  Will create VERIFIED bug for version: %s", next_version)

    all_versions = cve_versions

    tasks = []
    created_bugs = []
    # Track main issue per version (CVE or created bug) for dependency chain
    main_issue_by_version = {}
    all_cves_linked = []

    # Process each version
    for version in all_versions:
        logger.info("  Version %s:", version)

        # Create or get task (linked to epic via Epic Link field)
        task_key = create_task(
            client,
            cve_group.cve_id,
            cve_group.component,
            version,
            epic_key,
            cache,
            project,
            dry_run,
        )
        if task_key:
            tasks.append(task_key)

        # Check if CVEs exist for this version
        version_cves = all_cves_by_version.get(version, [])

        if version_cves:
            # Sort CVEs by key for consistent ordering (lowest = oldest)
            version_cves.sort(key=lambda x: x["key"])

            # Separate processed and unprocessed for logging
            unprocessed_cves = []
            for cve_data in version_cves:
                labels = cve_data.get("Labels", []) or []
                if cve_processed_label not in labels:
                    unprocessed_cves.append(cve_data)

            logger.info(
                "    %d CVEs (%d new)", len(
                    version_cves), len(unprocessed_cves)
            )

            # Store all CVEs with downstream component for dependency chain
            main_issue_by_version[version] = [
                VersionIssue(
                    key=cve["key"],
                    downstream_component=cve.get(
                        "Downstream Component Name", ""),
                )
                for cve in version_cves
            ]

            # Link all CVEs to task and add processed label
            for cve_data in version_cves:
                cve_key = cve_data["key"]
                all_cves_linked.append(cve_key)

                # Check if already processed
                labels = cve_data.get("Labels", []) or []
                already_processed = cve_processed_label in labels

                if already_processed:
                    logger.info("    %s (already processed)", cve_key)
                else:
                    # Get affects version for Target Backport Versions
                    affects_version = cve_data.get("Affects Version/s", [])

                    if dry_run:
                        logger.info(
                            "    [DRY RUN] Would link and label: %s", cve_key)
                        if affects_version:
                            version_names = [v["name"] for v in affects_version]
                            logger.info(
                                "    [DRY RUN] Would set Target Backport "
                                "Versions: %s", version_names)
                    else:
                        # Link to task
                        if task_key:
                            link_task_to_cves(client, task_key, [cve_key])

                        # Set Target Backport Versions to match Affects Version
                        if affects_version:
                            version_names = [v["name"] for v in affects_version]
                            client.update_issue(
                                cve_key,
                                {"Target Backport Versions": version_names}
                            )

                        # Add processed label
                        client.add_label(cve_key, cve_processed_label)
                        logger.info("    Linked: %s", cve_key)

    # Create VERIFIED bug for the next version after max CVE version
    if next_version:
        logger.info("  Version %s:", next_version)
        logger.info("    Creating VERIFIED bug (CVE fixed in earlier version)")

        # Create task for this version
        task_key = create_task(
            client,
            cve_group.cve_id,
            cve_group.component,
            next_version,
            epic_key,
            cache,
            project,
            dry_run,
        )
        if task_key:
            tasks.append(task_key)

        # Create VERIFIED bug
        is_latest = next_version == available_versions[-1]
        bug_key = create_verified_bug(
            client,
            cve_group.cve_id,
            cve_group.component,
            next_version,
            components,
            cache,
            is_latest,
            dry_run,
        )
        if bug_key:
            created_bugs.append(bug_key)
            main_issue_by_version[next_version] = [
                VersionIssue(key=bug_key, downstream_component="")
            ]

            # Link task to created bug
            if task_key:
                link_task_to_bug(client, task_key, bug_key, dry_run)

    # Create dependency chain between main issues (CVEs or bugs)
    link_version_dependencies(
        client, main_issue_by_version, available_versions, dry_run
    )

    return ProcessedResult(
        epic_key=epic_key,
        cve_id=cve_group.cve_id,
        component=cve_group.component,
        tasks=tasks,
        bugs=created_bugs,
        cves_linked=all_cves_linked,
    )


def process_cve_groups(
    client: JiraTool,
    cve_groups: Dict[str, CVEGroup],
    available_versions: List[str],
    repo_to_component: Dict[str, str],
    cve_processed_label: str,
    project: str,
    dry_run: bool = False,
) -> List[ProcessedResult]:
    """Process all CVE groups."""
    results = []

    for _, cve_group in cve_groups.items():
        result = process_cve_group(
            client,
            cve_group,
            available_versions,
            repo_to_component,
            cve_processed_label,
            project,
            dry_run,
        )
        results.append(result)

    return results


def print_summary(results: List[ProcessedResult], dry_run: bool = False):
    """Print a summary of all processed CVE groups."""
    if not results:
        print("\nNo CVE groups were processed")
        return

    total_epics = len(results)
    total_tasks = sum(len(r.tasks) for r in results)
    total_bugs = sum(len(r.bugs) for r in results)
    total_cves = sum(len(r.cves_linked) for r in results)

    # Count new vs existing issues
    new_tasks = sum(1 for r in results for t in r.tasks if is_dry_run_key(t))
    existing_tasks = total_tasks - new_tasks
    new_bugs = sum(1 for r in results for b in r.bugs if is_dry_run_key(b))
    existing_bugs = total_bugs - new_bugs
    new_epics = sum(1 for r in results if is_dry_run_key(r.epic_key))
    existing_epics = total_epics - new_epics

    # Print summary header
    print("")
    print("=" * 70)
    if dry_run:
        print("  SUMMARY (DRY RUN - no changes made)")
    else:
        print("  SUMMARY")
    print("=" * 70)

    # Totals section
    print("")
    print("  TOTALS")
    print("  " + "-" * 40)

    if dry_run:
        print(
            f"  Epics:      {total_epics:3d} "
            f"({existing_epics} existing, {new_epics} to create)"
        )
        print(
            f"  Tasks:      {total_tasks:3d} "
            f"({existing_tasks} existing, {new_tasks} to create)"
        )
        print(
            f"  Bugs:       {total_bugs:3d} "
            f"({existing_bugs} existing, {new_bugs} to create)"
        )
        print(f"  CVEs:       {total_cves:3d} to link")
    else:
        print(f"  Epics:      {total_epics:3d}")
        print(f"  Tasks:      {total_tasks:3d}")
        print(f"  Bugs:       {total_bugs:3d}")
        print(f"  CVEs:       {total_cves:3d} linked")

    # Per-group details
    print("")
    print("  DETAILS BY CVE GROUP")
    print("  " + "-" * 40)

    for i, result in enumerate(results):
        if i > 0:
            print("")

        # Group header
        print(f"  [{result.cve_id}] {result.component}")
        print(f"    Epic: {result.epic_key}")

        # Tasks
        if result.tasks:
            print(
                f"    Tasks ({len(result.tasks)}): {', '.join(result.tasks)}")

        # Bugs
        if result.bugs:
            print(f"    Bugs ({len(result.bugs)}): {', '.join(result.bugs)}")

        # CVEs
        if result.cves_linked:
            print(
                f"    CVEs ({len(result.cves_linked)}): "
                f"{', '.join(result.cves_linked)}"
            )

    print("")
    print("=" * 70)


def setup_logging(verbose: bool = False):
    """Configure logging for the application."""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )


def main():
    parser = argparse.ArgumentParser(
        description="Process CVE Vulnerability issues from Jira"
    )
    parser.add_argument(
        "--config",
        type=Path,
        default=DEFAULT_CONFIG_PATH,
        help="Path to config file (default: config.yaml)",
    )
    parser.add_argument(
        "--cve",
        dest="cve_filter",
        metavar="CVE-ID",
        help="Process only a specific CVE (e.g., CVE-2024-1234)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be done without making changes",
    )
    parser.add_argument(
        "-v", "--verbose", action="store_true", help="Enable verbose/debug logging"
    )
    parser.add_argument(
        "--project",
        default="OSASINFRA",
        help="Jira project for epics and tasks (default: OSASINFRA)",
    )
    args = parser.parse_args()

    setup_logging(args.verbose)

    # Load configuration
    config = load_config(args.config)
    cve_processed_label = config["cve_processed_label"]
    repo_to_component = config["repo_to_component"]
    logger.info("Loaded config from %s", args.config)

    # Get list of downstream components to query
    downstream_components = list(repo_to_component.keys())
    logger.info("Configured components: %s", downstream_components)

    client = JiraTool()

    logger.info("Fetching available target versions...")
    all_versions = client.get_field_allowed_values(
        "OCPBUGS", "Bug", "Target Version")
    available_versions = get_sorted_versions(all_versions)
    logger.info("Found %d numeric target versions", len(available_versions))
    logger.debug("Available versions: %s", available_versions)

    # Query Jira for all unprocessed Vulnerabilities
    if args.cve_filter:
        logger.info("Filtering for CVE: %s", args.cve_filter)
    issues = query_vulnerabilities(
        client, downstream_components, cve_processed_label, cve_filter=args.cve_filter
    )

    if not issues:
        logger.info("No unprocessed Vulnerabilities found")
        return

    cve_groups = group_issues_by_cve(issues, repo_to_component)
    logger.info("Found %d CVE groups", len(cve_groups))

    results = process_cve_groups(
        client,
        cve_groups,
        available_versions,
        repo_to_component,
        cve_processed_label,
        args.project,
        dry_run=args.dry_run,
    )
    print_summary(results, dry_run=args.dry_run)

    logger.info("Done")


if __name__ == "__main__":
    main()
